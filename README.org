#+TITLE: Memory benchmarking of multi-core processing in R and Python

*** Why does R's mclapply take so much memory?

Most useRs know about the parallel::mclapply function which can
potentially speed up R code (with respect to the standard lapply
function) by executing in parallel across several cores. However I did
not know that this speedup comes at the price of increased memory
usage. In this report I will explore the memory usage of mclapply.

In [[file:figure-kilobytes-used.R]] I benchmarked the memory usage of
=LAPPLY(1:N, returnXXX)= for several different choices of LAPPLY
(lapply, mclapply, my mclapply maxjobs hack), N (10, ..., 100000),
returnXXX. The figure below shows the memory usage as a function of
number of iterations (N) for two such returnXXX functions:

*returnNULL* is a function that just returns NULL. In this case
mclapply has a surprisingly significant linear memory overhead. For
example, with 4 CPU cores, about 60 megabytes of memory are required
on my system for mclapply to process a vector of N=100000 indices,
returning a list of 100000 NULL (orange solid lines). In comparison,
the standard lapply function has no such overhead (constant memory
usage, blue dotted lines). Using 2 cores rather than 4 seems to
decrease memory usage for large data sets. The dashed lines show my
[[file:kilobytes.used.R][maxjobs.mclapply]] hack which just repeatedly runs mclapply with a
vector of at most 1000 elements as its first argument.

[[file:figure-kilobytes-used.png]]

*returnDF* is a function that just returns a pre-computed data.frame
with 100 rows. In this case the memory overhead is also linear, but
the linear factor is much bigger (about 600 megabytes of memory
required to process N=100000 indices). Again the standard lapply
function has no such overhead. Interestingly, my "maxjobs" hack
results in a significant decrease in memory consumption! So in
practice I use this in [[https://github.com/tdhock/PeakSegJoint/blob/master/R/mclapply.R][PeakSegJoint]] to avoid having my jobs killed on
[[http://www.hpc.mcgill.ca/index.php/starthere/81-doc-pages/91-guillimin-job-submit][the guillimin supercomputer]].

References: =help(mclapply)=

#+BEGIN_SRC text
mc.preschedule: if set to ‘TRUE’ then the computation is first divided
          to (at most) as many jobs are there are cores and then the
          jobs are started, each job possibly covering more than one
          value.  If set to ‘FALSE’ then one job is forked for each
          value of ‘X’.  The former is better for short computations or
          large number of values in ‘X’, the latter is better for jobs
          that have high variance of completion time and not too many
          values of ‘X’ compared to ‘mc.cores’.
#+END_SRC

This benchmark is in the situation with few cores and large number of
values in X, so I kept mc.preschedule=TRUE.

*** Comparison with multiprocessing in Python

I adapted David Taylor's [[file:multiprocess.py]] code and ran it with
several parameters using [[file:multiprocess.sh]]. The figure below shows
an analogous benchmark for the multiprocessing module in Python:

[[file:figure-multiprocess.png]]

It seems that Python also suffers from the linear memory overhead
(solid lines), but it can be avoided by using the chunksize argument
to =Pool.map= (dashed lines). It works the same way as my "maxjobs"
hack (dashed lines). The regular map function has the least memory
usage (dotted lines). The memory overhead increases with the number of
cores (top panel, returnNone), but it is not significant for
non-trivial data (bottom panel).

*** R/Python conversion table

| R function         | Python function          |
|--------------------+--------------------------|
| lapply             | map                      |
| parallel::mclapply | multiprocessing.Pool.map |
| do.call            | apply                    |

Note: In R we have several functions which do basically the same thing
as Python's =map= but with slightly different inputs/outputs:

| R serial | R parallel | vector args | scalar args |
|----------+------------+-------------+-------------|
| lapply   | mclapply   |           1 |          0+ |
| sapply   | NA         |           1 |          0+ |
| mapply   | mcmapply   |          1+ |          0+ |
| Map      | mcMap      |          1+ |          0+ |

From =help(Map)= in R:

#+BEGIN_SRC text
‘Map’ is a simple wrapper to ‘mapply’ which does not attempt to
simplify the result, similar to Common Lisp's ‘mapcar’ (with
arguments being recycled, however).  Future versions may allow
some control of the result type.
#+END_SRC

=sapply= and =lapply= take the same outputs but =sapply= defaults to
simplify=TRUE:

#+BEGIN_SRC text
> Map(rep, 1:4, 4:1)
[[1]]
[1] 1 1 1 1

[[2]]
[1] 2 2 2

[[3]]
[1] 3 3

[[4]]
[1] 4

> mapply(rep, 1:4, 4:1)
[[1]]
[1] 1 1 1 1

[[2]]
[1] 2 2 2

[[3]]
[1] 3 3

[[4]]
[1] 4

> lapply(1:4, rep, 4:1)
Error in FUN(X[[i]], ...) : invalid 'times' argument
> lapply(1:4, rep, 5)
[[1]]
[1] 1 1 1 1 1

[[2]]
[1] 2 2 2 2 2

[[3]]
[1] 3 3 3 3 3

[[4]]
[1] 4 4 4 4 4

> sapply(1:4, rep, 5)
     [,1] [,2] [,3] [,4]
[1,]    1    2    3    4
[2,]    1    2    3    4
[3,]    1    2    3    4
[4,]    1    2    3    4
[5,]    1    2    3    4
> mapply(rep, 1:4, 5)
     [,1] [,2] [,3] [,4]
[1,]    1    2    3    4
[2,]    1    2    3    4
[3,]    1    2    3    4
[4,]    1    2    3    4
[5,]    1    2    3    4
> 
#+END_SRC

*** Reproducing these results

Copy works_with_R from
https://github.com/tdhock/dotfiles/blob/master/.Rprofile to your
~/.Rprofile, then on the command line cd to this directory.

Type =bash multiprocess.sh= to run a series of Python benchmarks and
save them in the =multiprocess-data/= directory. I did it twice so we
can see the variation between runs. Plot using =make
figure-multiprocess.png=.

To re-do the R benchmark type =make figure-kilobytes-used.png=.
